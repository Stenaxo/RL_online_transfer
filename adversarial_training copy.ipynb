{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_KNcPSTnJXo9"
   },
   "outputs": [],
   "source": [
    "# linear.svg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_zVanS9nJXpB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gJLzOCc8JXpB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JaQSJSv1JXpC"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)    \n",
    "\n",
    "model_cnn = nn.Sequential(\n",
    "      nn.Linear(784, 10)).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EoUXeSd4JXpD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RiFFSiDQJXpD"
   },
   "outputs": [],
   "source": [
    "def epoch(loader, model, opt=None):\n",
    "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err = 0.,0.\n",
    "    for X,y in loader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        yp = model(X)\n",
    "        loss = nn.CrossEntropyLoss()(yp,y)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SFhLONktJXpE"
   },
   "source": [
    "# Standard (i.e. non-robust) training on the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mSXi0Es9JXpE",
    "outputId": "43c5502d-1869-4a06-af94-b7e2bf691d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Err\tTest Err\tAdv Err\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5117c825f8fc437189388da87f2cf292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.133783\t0.097800\t0.389200\n",
      "0.099067\t0.089300\t0.405500\n",
      "0.092850\t0.084800\t0.430700\n",
      "0.088050\t0.081300\t0.450600\n",
      "0.085333\t0.081400\t0.458700\n",
      "0.082850\t0.081400\t0.463600\n",
      "0.082700\t0.081300\t0.464100\n",
      "0.082717\t0.081600\t0.466000\n",
      "0.082800\t0.081300\t0.467400\n",
      "0.082567\t0.081300\t0.468800\n"
     ]
    }
   ],
   "source": [
    "# This cell should run in less than 3 minutes\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_logreg = nn.Sequential(\n",
    "     Flatten(),\n",
    "     nn.Linear(784, 10)).to(device)\n",
    "opt = optim.SGD(model_logreg.parameters(), lr=1e-1)\n",
    "\n",
    "print(*(\"{}\".format(i) for i in (\"Train Err\", \"Test Err\", \"Adv Err\")), sep=\"\\t\")\n",
    "\n",
    "for t in tqdm(range(10)):\n",
    "    train_err, train_loss = epoch(train_loader, model_logreg, opt)\n",
    "    test_err, test_loss = epoch(test_loader, model_logreg)\n",
    "    if t == 4:\n",
    "        for param_group in opt.param_groups:\n",
    "            param_group[\"lr\"] = 1e-2\n",
    "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adversarial_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
